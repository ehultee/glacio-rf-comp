{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3177e1f9-2ce5-4dc2-8a2a-f61d6412e0c1",
   "metadata": {},
   "source": [
    "# Export basin-aggregated data\n",
    "In order to compile drought indices at the river-basin scale, we need to aggregate the glacial runoff for each basin and export it.  We produce a single CSV file for each GCM, SSP, and basin.  The columns of the CSV file should reflect the three glacier models compared here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbb3c5-b393-4221-92fa-76cf42656c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import date\n",
    "import collections\n",
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e332936-ac18-45b8-adaa-f9e962098473",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSPpaths = ['ssp126','ssp245','ssp370','ssp585']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c66c5-a17d-4e54-a7a4-a10b925da76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames = ['BCC-CSM2-MR','CAMS-CSM1-0','CESM2','CESM2-WACCM','EC-Earth3','EC-Earth3-Veg','FGOALS-f3-L','GFDL-ESM4',\n",
    "              'INM-CM4-8','INM-CM5-0','MPI-ESM1-2-HR','MRI-ESM2-0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dca7bd-7f14-4f02-bded-24f32218b5d2",
   "metadata": {},
   "source": [
    "## EDIT THESE to reflect your use case (fpath and which basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17800332-f0b9-499e-8c44-883cc7fdb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to each model's data folder\n",
    "fpath_glogem = '/Volumes/GoogleDrive/My Drive/Runoff-intercomparison/GloGEM-output/'\n",
    "fpath_pygem = '/Volumes/GoogleDrive/My Drive/Runoff-intercomparison/PyGEM/'\n",
    "fpath_oggm = '/Volumes/GoogleDrive/My Drive/Runoff-intercomparison/OGGM/lschuster/runs_2023.3/output/basins/gcm_from_2000_bc_2000_2019/'\n",
    "\n",
    "## Path where the processed output will go\n",
    "out_fpath = '/Users/lizz/Documents/Research/Runoff-intercomparison/basin_aggregated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd68815-6522-4854-a4af-61847d44cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_basins = {'RHONE': '6243'} ## fill with basin names (all caps) and GRDC basin codes of the basins you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8d705-44fe-4aa4-9865-2b05aa86b575",
   "metadata": {},
   "source": [
    "### Make a list of the relevant glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f8e8-e4c4-48fd-a398-0b99132887d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_glaciers_json(basin='all'):\n",
    "    '''\n",
    "    Select glaciers within a basin by MRBID from a json-file,\n",
    "    which is stored in the data directory.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    basin: str\n",
    "        String of MRBID or 'all'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    If basin is 'all' a list of all relevant glaciers is returned, for\n",
    "    initiating glacier simulations. If basin is a MRBID the list of glaciers\n",
    "    within that basin is returned.\n",
    "    \n",
    "    Copy of a function written by Erik Holmgren (2022) in holmgren_gha.utils\n",
    "    '''\n",
    "\n",
    "    fpath = '/Users/lizz/Documents/Research/Runoff-intercomparison/msc_thesis-multi_gcm/code/data/rgi_ids_per_basin.json' ## correct for local run\n",
    "    with open(fpath) as f:\n",
    "        basin_dict = json.load(f)\n",
    "\n",
    "    if basin.lower() != 'all':\n",
    "        glacier_list = basin_dict[basin]\n",
    "    else:\n",
    "        glacier_list = list(itertools.chain.from_iterable(basin_dict.values()))\n",
    "\n",
    "    return glacier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a75458-1534-4c44-9a6b-59170bcf8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_gls = {}\n",
    "for basin, code in which_basins.items():\n",
    "    basin_gls[basin] = select_glaciers_json(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99680d-7618-4c89-a577-ecf50739e1df",
   "metadata": {},
   "source": [
    "### Process GloGEM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3cdbe-be9c-4eec-b79a-197f1043fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_basin_glogem(basin_RGI_list, runoff_data, transpose=False):\n",
    "    \"\"\"\n",
    "    Sum GloGEM-derived runoff data from a basin, given a list of RGI IDs within\n",
    "    the basin.  Note this works differently if using for a single basin, GCM, SSP\n",
    "    (as in the Export-BasinData notebook) versus in a loop with many basins, GCMs,\n",
    "    SSPs (as in CentralEurope-3ModelAgg).\n",
    "    \n",
    "    Inputs:\n",
    "        basin_RGI_list: list, output from select_glaciers_json\n",
    "        runoff_data : df or Series, per-glacier runoff data\n",
    "        transpose: bool, optional\n",
    "            Default False reflects single-case usage as in Export-BasinData\n",
    "            Recover earlier utility, as in CentralEurope-3ModelAgg, by\n",
    "            setting to True.\n",
    "    \"\"\"\n",
    "    # Create new list to match our RGI formatting\n",
    "    new_basin_list = [int(str(x)[-4:]) for x in basin_RGI_list]\n",
    "    if transpose:\n",
    "        runoff_data = runoff_data.transpose()\n",
    "    \n",
    "    # Filter new_basin_list to keep only the indexes present in the DataFrame\n",
    "    new_basin_list = [x for x in new_basin_list if x in runoff_data.index]\n",
    "    \n",
    "    # Extract glaciers contained in the list from original df and create a new df\n",
    "    new_df = runoff_data.loc[new_basin_list].copy()\n",
    "    \n",
    "    # Sum the values of the glaciers within the basin\n",
    "    summed_basin_runoff = new_df.sum()\n",
    "    #print(summed_basin_runoff)\n",
    "    \n",
    "    return summed_basin_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9aa4c-799a-42e8-b49c-8a1456fe0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glogem_agg_runoff(basin_name, region_folder, region_fname, GCM, SSP, debug=False):\n",
    "    \"\"\"Compile a monthly time series of runoff, summed over\n",
    "    all glaciers in a given river basin.\n",
    "    \n",
    "    Inputs:\n",
    "        basin_name : str\n",
    "            The name of the basin, in all caps as in the List_MultiRegionBasins dict\n",
    "        region_folder: str\n",
    "            The part of the filepath that identifies the RGI region\n",
    "        region_fname: str\n",
    "            The part of the input filename that identifies the regional discharge data\n",
    "        GCM : str\n",
    "            The part of the filepath that names the GCM considered.\n",
    "            All valid choices are in modelnames list\n",
    "        SSP: str\n",
    "            Which SSP scenario we consider.  \n",
    "            Valid choices are 'ssp126','ssp245','ssp370','ssp585'\n",
    "        debug: bool, optional, default False\n",
    "            Whether to return intermediate output for examination\n",
    "            during debugging.  Default behavior is to return only\n",
    "            the aggregated runoff series.\n",
    "    \n",
    "    Output:\n",
    "        rs: pandas Series\n",
    "            Monthly runoff from all glaciers in this basin added together\n",
    "    \"\"\"\n",
    "    \n",
    "    discharge_df = pd.read_csv(fpath_glogem + region_folder + GCM + '/' + SSP  + '/' \n",
    "                          + region_fname + '_Discharge_r1.dat', \n",
    "                          sep='\\s+', header=None, skiprows=1, index_col=0)\n",
    "    area_df = pd.read_csv(fpath_glogem + region_folder + GCM  + '/' + SSP  + '/' \n",
    "                          + region_fname + '_Area_r1.dat', \n",
    "                          sep='\\s+', index_col=\"ID\")\n",
    "    \n",
    "    # Create new index using pandas date_range function\n",
    "    start_date = datetime.date(1980, 1, 1)\n",
    "    end_date = datetime.date(2100, 12, 1)\n",
    "    new_indices = pd.date_range(start_date, end_date, freq='MS').strftime('%Y-%m').tolist()\n",
    "\n",
    "    discharge_df.columns = pd.to_datetime(new_indices)\n",
    "    area_df = area_df[area_df.columns.repeat(12)]\n",
    "    area_df.columns = pd.to_datetime(new_indices)\n",
    "    \n",
    "    df_area_init = area_df.loc[:,'1980-01-01'].mul(1e6) ## convert from km2 to m2\n",
    "    \n",
    "    runoff = discharge_df.mul(df_area_init, axis=0)\n",
    "    \n",
    "    ## Aggregate using sum_basin, and convert from m3 to km3\n",
    "    rsum = sum_basin_glogem(select_glaciers_json(which_basins[basin_name]), runoff) * 1e-9\n",
    "    \n",
    "    if debug:\n",
    "        return rsum, runoff, df_area_init, discharge_df\n",
    "    else:\n",
    "        return rsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09dfcd-7bf8-426a-b2d2-8b9c9c8bcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs, rhone_tester, da, dd = glogem_agg_runoff('RHONE', 'RGI11-CentralEurope/files/', 'centraleurope', \n",
    "                                 modelnames[0], SSPpaths[0], debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7cd9-e8b0-45b0-98ef-65ff17c7799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c88a-0d03-40d8-bdc3-7eaff180d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.resample('A').sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3d8cdc-f1f4-4722-95cc-ca986b466a6c",
   "metadata": {},
   "source": [
    "### Process PyGEM data\n",
    "Read in as usual; select a given column for the GCM and SSP desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424132d-17bc-40b6-96b2-b614d2caf023",
   "metadata": {},
   "source": [
    "### Process OGGM data\n",
    "Read in as usual; select a given column for the GCM and SSP desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3b296-1883-4888-9bd0-95bd3a8d0c4a",
   "metadata": {},
   "source": [
    "### Write the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d317045-e690-4916-afb1-e7845c915124",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up filename to reflect what you're writing out, possibly in a nested loop\n",
    "out_fname = out_fpath+'runoff_{}_{}_{}.csv'.format(GCM, ssp, basin_name) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
